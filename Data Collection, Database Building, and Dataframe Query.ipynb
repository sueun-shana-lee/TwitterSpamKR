{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89567262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import snscrape\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from datetime import timedelta\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e99c3cc",
   "metadata": {},
   "source": [
    "# Search Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e2bb70",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fd765a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to set up and write on SQL database\n",
    "from sqlite3 import Error \n",
    "\n",
    "def sql_connection(dbname):\n",
    "    try:\n",
    "      conn = sqlite3.connect(dbname)\n",
    "      return conn\n",
    "    except Error:\n",
    "      print(Error)\n",
    "\n",
    "\n",
    "def table_insert(tablename, conn, rows, col_assign):\n",
    "    \n",
    "    #table name = name the table you will put in\n",
    "    #conn = connection, get it by the function above\n",
    "    #rows = data to put in\n",
    "    #col_assign = sql needs the values to be assigned\n",
    "    try:\n",
    "        colnum=len(rows[0])\n",
    "        cursorObj = conn.cursor()\n",
    "        cursorObj.execute(\"CREATE TABLE \"+tablename+col_assign)\n",
    "        sqlite_insert_query_format = \"INSERT INTO {0} VALUES {1};\"\n",
    "        query_ques='('+''.join(['?,']*(colnum-1)+['?'])+')'\n",
    "        sqlite_insert_query=sqlite_insert_query_format.format(tablename,query_ques)\n",
    "        cursorObj.executemany(sqlite_insert_query, rows)\n",
    "        conn.commit()      \n",
    "        print(\"Number of records after inserting rows:\")\n",
    "        cursor = cursorObj.execute('SELECT * from '+tablename+';')\n",
    "        print(len(cursor.fetchall()))\n",
    "        \n",
    "    except sqlite3.OperationalError:\n",
    "        ans=input(\"The table already exists. Do you want to update it? Y/N: \")\n",
    "        if ans == 'Y':\n",
    "            sql_stmt = \"DROP TABLE \"+str(tablename)\n",
    "            conn.cursor().execute(sql_stmt)\n",
    "            table_insert(tablename, conn, rows, col_assign)\n",
    "        else: ('Insertion Cancelled')\n",
    "        \n",
    "def sql_assign_str(colnames,listoflists):\n",
    "    width=len(listoflists[0])\n",
    "    df=pd.DataFrame(listoflists)\n",
    "    dtypelist=df.infer_objects().dtypes\n",
    "    result='('\n",
    "    for i in range(0,width):\n",
    "        if dtypelist[i] == object: entry_type='text'\n",
    "        elif str(dtypelist[i]) == 'int64': entry_type='real' \n",
    "                \n",
    "        if i ==0:\n",
    "            result=result+colnames[i]+' '+entry_type\n",
    "        else:\n",
    "            result=result+', '+colnames[i]+' '+entry_type\n",
    "    result=result+')'\n",
    "    return result\n",
    "\n",
    "#frequently used variables\n",
    "assignstr_tweets='(Tweeted_Date text, Content text, Username text, Replies real, RTs real, Likes real, QRTs real, Source text, Hashtags text)'\n",
    "assignstr_users='(Username text, Displayname text, Created_Date text, Followers real, Friends real, Statuses real, Favorites real, Listeds text, Medias text)'\n",
    "conn=sql_connection('TwitterProject.db')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4012f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Snscrape search functions\n",
    "def search_scrape(search_word,limit):\n",
    "    tweets = [] #initiate arrays\n",
    "    users = []\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(search_word).get_items()):\n",
    "        if i>limit:\n",
    "            break\n",
    "        t = tweet #for simplicity\n",
    "\n",
    "        \n",
    "        #SQLite does not take iterable items to be saved in their system.\n",
    "        #I need to manually parse them later if I want to access to the hashtags\n",
    "        #empty lists for placeholders for the tweets without hashtags\n",
    "        try:\n",
    "            tweets.append([t.date.date().strftime('%Y-%m-%d'), t.content,t.user.username, t.replyCount,\n",
    "                            t.retweetCount, t.likeCount, t.quoteCount, t.sourceLabel, t.hashtags.str.join('-')])\n",
    "        \n",
    "            users.append([t.user.username, t.user.displayname, t.user.created.date().strftime('%Y-%m-%d'),\n",
    "                            t.user.followersCount, t.user.friendsCount, t.user.statusesCount, t.user.favouritesCount,\n",
    "                            t.user.listedCount, t.user.mediaCount])\n",
    "        except AttributeError:\n",
    "            tweets.append([t.date.date().strftime('%Y-%m-%d'), t.content,t.user.username, t.replyCount,\n",
    "                            t.retweetCount, t.likeCount, t.quoteCount, t.sourceLabel, ''])\n",
    "        \n",
    "            users.append([t.user.username, t.user.displayname, t.user.created.date().strftime('%Y-%m-%d'),\n",
    "                            t.user.followersCount, t.user.friendsCount, t.user.statusesCount, t.user.favouritesCount,\n",
    "                            t.user.listedCount, t.user.mediaCount])\n",
    "    return tweets, users\n",
    "\n",
    "#Snscrape Hashtag search functions\n",
    "def Hashtag_scrape(search_word,limit):\n",
    "    tweets = [] #initiate arrays\n",
    "    users = []\n",
    "    for i,tweet in enumerate(sntwitter.TwitterHashtagScraper((search_word)).get_items()):\n",
    "        if i>limit:\n",
    "            break\n",
    "        t = tweet #for simplicity\n",
    "\n",
    "        \n",
    "        #SQLite does not take iterable items to be saved in their system.\n",
    "        #I need to manually parse them later if I want to access to the hashtags\n",
    "        #empty lists for placeholders for the tweets without hashtags\n",
    "        try:\n",
    "            tweets.append([t.date.date().strftime('%Y-%m-%d'), t.content, t.user.username, t.replyCount,\n",
    "                            t.retweetCount, t.likeCount, t.quoteCount, t.sourceLabel, t.hashtags.str.join('-')])\n",
    "        \n",
    "            users.append([t.user.username, t.user.displayname, t.user.created.date().strftime('%Y-%m-%d'),\n",
    "                            t.user.followersCount, t.user.friendsCount, t.user.statusesCount, t.user.favouritesCount,\n",
    "                            t.user.listedCount, t.user.mediaCount])\n",
    "        except AttributeError:\n",
    "            tweets.append([t.date.date().strftime('%Y-%m-%d'), t.content, t.user.username, t.replyCount,\n",
    "                            t.retweetCount, t.likeCount, t.quoteCount, t.sourceLabel, ''])\n",
    "        \n",
    "            users.append([t.user.username, t.user.displayname, t.user.created.date().strftime('%Y-%m-%d'),\n",
    "                            t.user.followersCount, t.user.friendsCount, t.user.statusesCount, t.user.favouritesCount,\n",
    "                            t.user.listedCount, t.user.mediaCount])\n",
    "    return tweets, users\n",
    "\n",
    "#Identify users, and get their second tweets (possibly not the tweet we searched for)\n",
    "#Bad time complexity. Don't try too many\n",
    "def Scraped_users_sixth(search_word,limit):\n",
    "    tweets = [] #initiate arrays\n",
    "    users = []\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper((search_word)).get_items()):\n",
    "        if i>limit:\n",
    "            break\n",
    "        t = tweet #for simplicity\n",
    "        if t.user.statusesCount>10: #If the user made more than 10 tweets (active):\n",
    "            users.append([t.user.username, t.user.displayname, t.user.created.date().strftime('%Y-%m-%d'),\n",
    "                            t.user.followersCount, t.user.friendsCount, t.user.statusesCount, t.user.favouritesCount,\n",
    "                            t.user.listedCount, t.user.mediaCount])\n",
    "            \n",
    "            t2=search_scrape('from:@'+t.user.username,20)[0][5]\n",
    "            tweets.append(t2)                \n",
    "        else: pass\n",
    "    return tweets, users   \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4d552",
   "metadata": {},
   "source": [
    "I found that my functions didn't handle hashtag collection error well and made everything empty string. I will get it back in the data anlaysis stage with parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f1f76",
   "metadata": {},
   "source": [
    "## Clean search\n",
    "Seraching for tweets that's ostensibly Clean. Will analyze and prove how clean the search are in the analysis stage.\n",
    "Clean means tweets and accounts made by real users, not spams accounts. It may include people who are using Twitter as vulgar uses, but I don't defie them as 'dirty' as they are real users and do not produce illicit promotional posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582f729",
   "metadata": {},
   "source": [
    "### Tweets about Trending Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "11694f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/search?q=바퀴벌레\n",
      "https://twitter.com/search?q=#에스엠_레드벨벳_콘서트_돌려놔\n",
      "https://twitter.com/search?q=임창균 우비\n",
      "https://twitter.com/search?q=소속사 이적\n",
      "https://twitter.com/search?q=서울페스타\n",
      "https://twitter.com/search?q=괜찮으신가요\n",
      "https://twitter.com/search?q=무정부상태\n",
      "https://twitter.com/search?q=전석 13만원\n",
      "https://twitter.com/search?q=콘서트 취소\n",
      "https://twitter.com/search?q=인스타 압수\n",
      "https://twitter.com/search?q=양성애자\n",
      "https://twitter.com/search?q=인명피해\n",
      "https://twitter.com/search?q=워터파크\n",
      "https://twitter.com/search?q=인스타 해킹\n",
      "https://twitter.com/search?q=잠실 시야\n",
      "https://twitter.com/search?q=헌트 후기\n",
      "https://twitter.com/search?q=주경기장\n",
      "https://twitter.com/search?q=남부지방\n",
      "https://twitter.com/search?q=집중호우\n",
      "https://twitter.com/search?q=재택근무\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from urllib.parse import quote_plus\n",
    "from urllib.parse import unquote_plus\n",
    "\n",
    "scraper = sntwitter.TwitterTrendsScraper()\n",
    "\n",
    "keywords=[]\n",
    "for trend in scraper.get_items():\n",
    "    print(unquote_plus(str(trend)))\n",
    "    keywords.append(str(trend).partition('?q=')[2])\n",
    "\n",
    "#twitter provides 20 trending keywords by default\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of people speaking about trending posts\n",
    "\n",
    "key_tweets = []\n",
    "key_users = []\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for keyword in keywords:\n",
    "    kt,ku = search_scrape(keyword,100) #20 keywords, \n",
    "    key_tweets.append(kt)\n",
    "    key_users.append(ku)\n",
    "\n",
    "#hierarchy key_tweets/users[index of keyword][index of each tweet][index of items]\n",
    "#use concat to make it a flattened list, but we sometimes have to kick out some automated tweet's keywords\n",
    "#manually check it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "6a9b109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(key_tweets).to_csv('key_tweets.csv')\n",
    "pd.DataFrame(key_users).to_csv('key_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "868281fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['2022-08-10', '너 강남사는 바퀴벌레지 https://t.co/ttwqZHQkFg', 'latte_0425', 0, 0, 0, 0, 'Twitter for Android', '']\n",
      "\n",
      "1\n",
      "['2022-08-10', '@RVsmtown BETTER TREATMENT FOR @RVsmtown \\n\\n#SM_여돌차별_공론화\\n#에스엠_레드벨벳_콘서트_돌려놔 \\n@SMTOWNGLOBAL', 'moaluvieeeee', 0, 0, 0, 0, 'Twitter for Android', '']\n",
      "\n",
      "2\n",
      "['2022-08-10', '임창균 직캠\\n임창균 셀카\\n임창균 금발\\n임창균 흑발\\n임창균 랩 찢어라\\n임창균 우비\\n임창균 갓댐\\n임창균 막내\\n임창균 고양이\\n임창균 귀여워\\n임창균 사랑해 https://t.co/wCHzPyZgPk', 'kyunrill', 0, 0, 0, 0, 'Twitter for iPad', '']\n",
      "\n",
      "3\n",
      "['2022-08-10', '하성운, 24일 미니 7집 발매 확정…소속사 이적 후 첫 앨범[공식] (출처 : 뉴스엔 | 네이버 TV연예) https://t.co/aHm9ieKc2P', 'sarangsungwoon', 0, 0, 0, 0, 'Twitter for Android', '']\n",
      "\n",
      "4\n",
      "['2022-08-10', '서울페스타 엔시티드림 팬석 3층 35구역 2열 양도합니다 (34,36 사이에 구역 있습니다)\\n\\n1장 3.0\\n\\n팔찌랑 티켓 다 드립니다 공연장 앞 직거래 가능\\n\\n엔시티드림 서울페스타 시즈니 팬석 믐뭔봄 제노 해찬 마크 지성 천러 런쥔 재민 NCT NCT DREAM nctdream', 'dhhwsyyshwhzjjw', 0, 0, 0, 0, 'Twitter for iPhone', '']\n",
      "\n",
      "5\n",
      "['2022-08-10', '@minggu_art 콘서트 중간에 쓰러지셔서 의무실러 데랴왔습니다ㅠㅠ 괜찮으신가요?!', 'Ol_Moonlight', 0, 0, 0, 0, 'Twitter for Android', '']\n",
      "\n",
      "6\n",
      "['2022-08-10', '국민들은 수해로 목숨을 잃고 이재민이 됐는데 웃으면서 윤희근한테 경찰청장 임명장 주는 윤석열이나 꼽사리로 사진 찍는 행안부 장관 이상민이나. 돌았다 무정부상태. https://t.co/R9L3b36TzE', 'berlinmingming', 0, 3, 2, 0, 'Twitter for iPhone', '']\n",
      "\n",
      "7\n",
      "['2022-08-10', '내 자리 있을 가능성은 올라갔지만 전석 13만원이라니 개양아치새끼들...^^', 'gokguma', 0, 0, 0, 0, 'Twitter for iPhone', '']\n",
      "\n",
      "8\n",
      "['2022-08-10', '콘서트 공지 장소 바뀌는 건 맞는 것 같은데… 광클에도 장소만 내려가있고 원래 포스터에 [Olympic stadium]이라고 써져있었어서 그 장소 바꾸려구 내린 거 아닐까요? 어찌됐든 공지 올려놓고 몇 시간만에 다시 취소라고 할 대가리총맞은사람들은 아닐 테니…', 'jen5yoit', 0, 1, 1, 1, 'Twitter for iPhone', '']\n",
      "\n",
      "9\n",
      "['2022-08-10', 'ㅅㅂ당장인스타압수해\\n왜인스타에빨가벗은걸올리는거야?', 's_sng__', 0, 0, 0, 0, 'Twitter for Android', '']\n",
      "\n",
      "10\n",
      "['2022-08-10', '@p5jbjLMydMicDfk 제가 빨아드릴게요 제꺼도 빨아주세요 디엠좀 보내주세요!', 'wantsex12dkd', 0, 0, 0, 0, 'Twitter Web App', '']\n",
      "\n",
      "11\n",
      "['2022-08-10', '#인스타압수 #인스타해킹 #집중호우 #인명피해 #추석연휴 #재난상황 #테슬라 #선선예매\\nhttps://t.co/MAI7P4YN6i', 'HoHoday11', 0, 0, 0, 0, 'Twitter for Android', '']\n",
      "\n",
      "12\n",
      "['2022-08-10', '여ㅡ름이다ㅡ!!\\n바다못감.\\n워터파크못감.\\n큐로나 조심.', 'neung1570', 1, 0, 1, 0, 'Twitter for Android', '']\n",
      "\n",
      "13\n",
      "['2022-08-10', '인스타 해킹할수있는사람없어요? 급해요 ㅠㅠ', 'rkWkrha', 0, 0, 1, 0, 'Twitter for iPhone', '']\n",
      "\n",
      "14\n",
      "['2022-08-10', '서울페스타 b석 2구역 4열 티켓 있으신분\\n찾아요\\n아직 좌석티켓으로 교환 안했어요\\n추금0 가격제시해주세요\\n3,5열도 괜찮아용\\n\\n서울페스타 버블라이브 잠실 시야 포카 양도 교환 더보이즈 엔시티드림 르세라핌 팬석 스트레이키즈 좌석', 'geolae22335232', 0, 0, 1, 0, 'Twitter for iPhone', '']\n",
      "\n",
      "15\n",
      "['2022-08-10', '그 시대에 고통받고 희생당한 분들을 생각하면 한참 모자란다고 생각한다. 그 끔찍한 고통을 일부나마 전달하기에 꼭 필요한 최소한이었다.\\n\\n역시... 감독님이 고문씬에 대해서 생각 안했을리 없다 여겼음. \\n#헌트 #헌트후기 https://t.co/mJMZ4k2fc8', 'shabu_7', 0, 6, 4, 0, 'Twitter Web App', '']\n",
      "\n",
      "16\n",
      "['2022-08-10', '주경기장은.. 플로어나 1층 아님 가는 이유가 없뜸', 'jjumjjum_176832', 0, 0, 0, 0, 'Twitter for iPhone', '']\n",
      "\n",
      "17\n",
      "['2022-08-10', '웃기는 일임 서울사람들이 오세훈 뽑아두고 피해생기니까 남부지방에 기우제하라고 보내줘야한다는식의 트윗이... (안뽑은트친들한테는 미안하지만) 조금 기만적임', 'jinjja_lov3', 0, 0, 0, 0, 'Twitter for Android', '']\n",
      "\n",
      "18\n",
      "['2022-08-10', '김성제 의왕시장, 집중호우 피해지역 현장 점검…여름휴가 반납', 'epink_7221z', 0, 0, 0, 0, 'Twitter Web App', '']\n",
      "\n",
      "19\n",
      "['2022-08-10', '@X0X_DoHun 재택근무라고 우기는겁니다(?)', 'WorthThemAll', 0, 0, 0, 0, 'Twitter for iPhone', '']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print search results and see the quality of tweets\n",
    "\n",
    "for i in range(0,20):\n",
    "    print(i)\n",
    "    print(key_tweets[i][5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a69d30cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#flatten the list to hierarcy: key_tweets/users[index of each tweet][index of items]\n",
    "key_tweets_flat=[]\n",
    "key_users_flat=[]\n",
    "for i in range(0,20):\n",
    "    key_tweets_flat=key_tweets_flat+key_tweets[i]\n",
    "    key_users_flat=key_users_flat+key_users[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83969f3",
   "metadata": {},
   "source": [
    "### Tweets about Official Twitter Creators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ae8ec845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-08-08', '‘개발자가 되고 싶다면 트위터하세요’ \\n트위터 크리에이터 프로그램에 참여하신 클로이님 @chloeelog 인터뷰가 매경에 실렸습니다.\\n트위터만의 독특한 확장성과 크리에이터 생태계가 잘 드러난 기사 감사드려요👍@HyejiPark5 @damdadi_dami \\nhttps://t.co/BnGDW5THUD', 'jangp0p', 0, 4, 8, 0, 'Twitter for iPhone', ''] ['jangp0p', 'Grace Jang', '2011-09-29', 148, 795, 593, 894, 9, 96]\n"
     ]
    }
   ],
   "source": [
    "#Who are either twitter official creators or talking about official creators\n",
    "#This is an amazingly clean keyword\n",
    "#I assume twitter is keeping their eyes on this query for the quality of their promotions on creators\n",
    "Creator_Tweets, Creator_Users = search_scrape('트위터 크리에이터',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3d60c1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-08-07', '▼▼ㅇㅑ밤공식ㅌㅡ위ㅌㅓ▲♠▽\\n\\n#FLO_크리에이터_모집 #망가ㅅㅏ이트\\n#ㅅㅡㅌㅠㅇㅓㄷㅣㅅㅡ과외\\n\\n♠주_소  https://t.co/G0rvSL3MJQ\\n\\n늘봄넷긴급 https://t.co/vx4CFWe8TA', 'loveegg_0408', 0, 0, 0, 0, 'Twitter Web App', '']\n"
     ]
    }
   ],
   "source": [
    "#One blatant spam tweet found\n",
    "print(Creator_Tweets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a2660872",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pop it out\n",
    "Creator_Tweets.pop(2)\n",
    "Creator_Users.pop(2)\n",
    "\n",
    "len(Creator_Tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8bbb5",
   "metadata": {},
   "source": [
    "### Idol Foodie Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "52d767f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idol_hashtags=('위EAT_인EAT','승윤이의_맛집_PAGE','이맛집_찐받네','마이노_마이무','훈슐랭_여기도가봤니','정한아_마니머거여ㅎㅎ','조슈아_먹어보슈아','순영아_이거_맛있어'\n",
    ",'원우야_여기_테이스티','도겸이도_도아할_맛집','박지성_단1g도안줌','제노의_맛그당어','나나의_맛집탐방기','정우의_원데이씩스밀','먹어봤도영','백현이를_위한_맛집투어'\n",
    ",'몬베베가_몬베베에게_추천하는_맛집','채형원_너는세입도못먹겠지','지민이와_밥밥밥을먹어요','정국아_같이먹짱','머거스트디','뷔슐랭','기범아_나혼자먹는거_아니야'\n",
    ",'ㄷㅂㅇㅈ','이션같이찌자','오늘은웬디여기','강다니엘_염염긋','우석아_맛집으로_우따따따','승연아_우즈야_여기야','황제님을위한메뉴판','예의있게_추천해'\n",
    ",'지훈아_여기가_맛있지훈','김재환_밥은_잘먹고있냐')\n",
    "\n",
    "#Got these hashtags from https://twitter-michelin-guide.netlify.app/hashtag.html\n",
    "#Most searched hashtags used by Kpop idol fandoms to suggest their restraunt recommendations to their fans and idols\n",
    "#Idol fans keep the quality of their hashtags clean so that their idols can be exposed more with searches and retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "6a1fa592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1657\n"
     ]
    }
   ],
   "source": [
    "Hash_Tweets=[]\n",
    "Hash_Users=[]\n",
    "for tag in idol_hashtags:\n",
    "    ht, hu= Hashtag_scrape(tag,50)\n",
    "    Hash_Tweets=Hash_Tweets+ht\n",
    "    Hash_Users=Hash_Users+hu\n",
    "print(len(Hash_Tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc34d6da",
   "metadata": {},
   "source": [
    "### Who opened Spaces, limited to Korean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "afc5d7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "['2022-08-08', '@ilove_lve 헐 깅 멋쪄요..😍', 'ihaveive123', 1, 0, 0, 0, 'Twitter for Android', '']\n"
     ]
    }
   ],
   "source": [
    "#Users who recently opened a space, and their 6th recent tweets\n",
    "#Space is a public voicechat of which their 'open' action is given to active users for AB testing \n",
    "Space_Tweets,Space_Users=Scraped_users_sixth('filter:spaces lang:ko',1000)\n",
    "print(len(Space_Tweets))\n",
    "print(Space_Tweets[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1403a2",
   "metadata": {},
   "source": [
    "## To SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "46f63093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The table already exists. Do you want to update it? Y/N: Y\n",
      "Number of records after inserting rows:\n",
      "1818\n",
      "The table already exists. Do you want to update it? Y/N: Y\n",
      "Number of records after inserting rows:\n",
      "1818\n",
      "The table already exists. Do you want to update it? Y/N: Y\n",
      "Number of records after inserting rows:\n",
      "500\n",
      "The table already exists. Do you want to update it? Y/N: Y\n",
      "Number of records after inserting rows:\n",
      "500\n",
      "Number of records after inserting rows:\n",
      "1657\n",
      "Number of records after inserting rows:\n",
      "1657\n",
      "Number of records after inserting rows:\n",
      "1001\n",
      "Number of records after inserting rows:\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "#Data types of tweets and users are same for all results, so made a universal SQL assignment string\n",
    "tweet_assignstr=sql_assign_str(['Tweeted_Date','Content','Username','Replies','RTs','Likes','QRTs','Source','Hashtags'],key_tweets_flat)\n",
    "user_assignstr=sql_assign_str(['Username','Displayname','Created_Date','Followers','Friends','Statuses','Favorites','Listeds','Medias'],key_users_flat)\n",
    "\n",
    "#2020 items, Based on Trending Keywords(Aug-10-2022)\n",
    "table_insert('Key_Tweets', conn, key_tweets_flat, tweet_assignstr)\n",
    "table_insert('Key_Users', conn, key_users_flat, user_assignstr)\n",
    "\n",
    "#500 items, Search Result of \"트위터 크리에이터\", One spam tweet manually identified and dropped\n",
    "table_insert('Creator_Tweets', conn, Creator_Tweets, tweet_assignstr)\n",
    "table_insert('Creator_Users', conn, Creator_Users, user_assignstr)\n",
    "\n",
    "#1657 items, Search Result of Poplular idol foodie hashtags\n",
    "table_insert('Hash_Tweets', conn, Hash_Tweets, tweet_assignstr)\n",
    "table_insert('Hash_Users', conn, Hash_Users, user_assignstr)\n",
    "\n",
    "#1001 items, Users who recently opened a space (public voicechat), and their 6th recent tweets\n",
    "table_insert('Space_Tweets', conn, Space_Tweets, tweet_assignstr)\n",
    "table_insert('Space_Users', conn, Space_Users, user_assignstr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb05e634",
   "metadata": {},
   "source": [
    "## Dirty Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7e5e9",
   "metadata": {},
   "source": [
    "### Manually Found Targeted Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e0602eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Targeted Keyword recognition -> Classify it into general and specific\n",
    "JJ_Tweets, JJ_Users = search_scrape('제주아이스크림 since:2022-05-01',300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abecdcb",
   "metadata": {},
   "source": [
    "### Communication Methods Used by Spam Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6e87174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display name includes :ㄹㅏ인 ㄹr인...\n",
    "Line_Tweets = []\n",
    "Line_Users = []\n",
    "lt,lu = search_scrape('ㄹr인',500)\n",
    "Line_Tweets = Line_Tweets + lt\n",
    "Line_Users = Line_Users +lu\n",
    "lt,lu = search_scrape('ㄹㅏ인',500)\n",
    "Line_Tweets = Line_Tweets + lt\n",
    "Line_Users = Line_Users +lu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34ac594",
   "metadata": {},
   "source": [
    "## To SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "369293b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records after inserting rows:\n",
      "110\n",
      "Number of records after inserting rows:\n",
      "110\n",
      "Number of records after inserting rows:\n",
      "1002\n",
      "Number of records after inserting rows:\n",
      "1002\n"
     ]
    }
   ],
   "source": [
    "#301 items, specific targeted Keyword I manually found\n",
    "table_insert('Jeju_Tweets', conn, JJ_Tweets, tweet_assignstr)\n",
    "table_insert('Jeju_Users', conn, JJ_Users, user_assignstr)\n",
    "\n",
    "#1002 items, Usernames including contact platform often used for illicit convos\n",
    "table_insert('Line_Tweets', conn, Line_Tweets, tweet_assignstr)\n",
    "table_insert('Line_Users', conn, Line_Users, user_assignstr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433de2db",
   "metadata": {},
   "source": [
    "## Save SQL database into csv\n",
    "I'm unfamiliar with SQL on python yet, so I want to save data in csv just in case I didn't safely saved data in TwitterProject.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cb9027c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                      ⌚\\n지글지글 사하구맛집 린헤어 제주아이스크림맛집 \\n📓\n",
      "1                            🐼\\n제주아이스크림 여행 일탈 #호기심 \\n📿\n",
      "2                      💞\\n지글지글 사하구맛집 린헤어 제주아이스크림맛집 \\n🐍\n",
      "3                           🍉\\n제주아이스크림맛집 인턴 알바 #혼술 \\n⏸\n",
      "4                       ‍♂️\\n제주아이스크림맛집 인턴 알바 #혼술  \\n🐈‍\n",
      "5                               ♾\\n제주아이스크림맛집 인턴 알바 #혼술\n",
      "6                               🍣\\n제주아이스크림맛집 인턴 알바 #혼술\n",
      "7    타이밍\\n책상인테리어\\n천일\\n천안호두\\n힘이되는글\\n떠나고싶다\\n상서구룸싸룽\\n상...\n",
      "8    제주시카페\\n송도맛집마포소금구이\\n태백코로나\\n무역\\n셀프레벨링업체\\n촬영소품\\n서...\n",
      "9    패스트픽\\n브라운브레스\\n남원다방\\n리조또\\n양산시모텔\\n박자\\n채식식단\\n시청후\\...\n",
      "Name: Content, dtype: object\n",
      "0          은평출장안ㅁㅏ\\n출장호텔\\nW2Ena\\n은평유부녀\\n#섹트\n",
      "1       ‍❤️‍\\n정읍출장만남 아가씨  천안출장안마  셀기꾼  \\n❤️\n",
      "2       ‍🔥\\n강원테라피출장  선팔환영 밀양  하남동출장마사지  \\n🧡\n",
      "3    ❣\\n사천탕수육  전공원 애니메이트강남역채팅후기  진주개인스냅 \\n💞\n",
      "4          ❤️‍\\n배우  사천페이만남 경기악화  유산소운동  \\n💖\n",
      "5                💓\\n오겹살 오늘의유머  오프남 일상소통 \\n🧡\n",
      "6              💕\\n보성맛집 롱다리  육변기 사상출장안마  \\n🧡\n",
      "7              💕\\n빙수 키스방   비토성감 그로우커넥트  \\n❣\n",
      "8           💕\\n수원만남  포항당일만남사이트  코디  횡성군 \\n💓\n",
      "9               💕\\n출장마사지제주 예천오피 사진 대리구매 \\n💞\n",
      "Name: Content, dtype: object\n",
      "0    📍더세임 카페\\n(with. @pukistal19 )\\n\\n더세임 갈 때마다 도넛 ...\n",
      "1    📍 광주 전대후문 주디마리\\n\\n푸딩이 왜그렇게 유명한지 알 것 같아요… 탱글탱글 ...\n",
      "2    📍홍대 츠케루\\n\\n츠케멘은 처음 먹어보는 거였는데 너무 맛있었어요! 양도 많아서 ...\n",
      "3    📍홍대 피오니\\n\\n딸기 빙수 맛집 🍓🍧 \\n빙수 얼음 자체가 달달해서 새콤달콤 너...\n",
      "4    📍연남 수상한키친\\n\\n연어 맛집 🧡 크림연어메밀면도 너무 맛있구 지라시스시도 짱이...\n",
      "5    📍연남 네시사분\\n\\n지금은 체리시즌이더라구요! 생체리를 갈아서 만든 체리 스무디 ...\n",
      "6    📍동명동 소뇨\\n\\n빙수 맛집!! 빙수도 너무 예쁘고 생과일이 잔뜩이라 최고예요 (...\n",
      "7    📍코엑스 샤이바나\\n\\n맥앤치즈 쫀맛 💙🍀\\n\\n#위EAT인EAT\\n#승윤이의_맛집...\n",
      "8    📍합정 멘야준 \\n#위너투어 \\n#위EAT_인EAT https://t.co/wVfe...\n",
      "9    📍성수 고수포차\\n#위EAT_인EAT\\n#승윤이의_맛집_PAGE\\n#이맛집_찐받네\\...\n",
      "Name: Content, dtype: object\n",
      "0    디엠이나 전화할 사람 맘찍이나 디엠 !!!!!! \\n반갑게 환영 해줌!!!! (아파...\n",
      "1                 개타쉽만 나가는거지ㅡ? 어 그려...6인으로 난ㅇ아줘서 고망어..\n",
      "2                                @ilove_lve 헐 깅 멋쪄요..😍\n",
      "3                                 @pollappoo 오늘세계고양이의날\n",
      "4    @imboriii @Bug4city @bug4what 악 ㅋㅋㅋㅋ 뿌듯해여 보리님!...\n",
      "5                         지코 영통팬싸 베발 누가 지코지디 콜라보 물어봐부라\n",
      "6    글씨만 써 있는데 영상이 자동재생되네요;;이상하다...\\n근데 이거 너무 찌라시 문...\n",
      "7             ⬇️⬇️⬇️⬇️⬇️⬇️⬇️⬇️ https://t.co/Pq3sBijc8v\n",
      "8             제 스페이스에 참여해 주세요! https://t.co/UlK7ByppqO\n",
      "9                      스제코드\\n\\nhttps://t.co/s70A4ya7B5\n",
      "Name: Content, dtype: object\n",
      "0    실트 ㅂㅏ퀴벌레 클릭하니 영상이 뜨는구만,,비위 안좋으신분들은 실트 클릭하지 마세요...\n",
      "1    실트 바퀴벌레....\\n들어가지마........\\n그래..트위터에벌레이름이실트면 9...\n",
      "2    추종벌레\\n\\n여기는 바퀴벌레가 많아\\n설탕을 추종하는 버러지들\\n악마의 본성을 타...\n",
      "3    정말 바퀴벌레 만도 못한 굥 정권이다\\n우리나라 땅에서 전쟁연습 반대하는 현수막 펼...\n",
      "4                                    실트 바퀴벌레 뭐야\\n기절하겠네\n",
      "5                 너 강남사는 바퀴벌레지 https://t.co/ttwqZHQkFg\n",
      "6    엘리 아론 : \"나한테 의존해 달콤한 꿀빨았어? 내가 마구 흘리고 있었던 달콤한 과...\n",
      "7      이렇게된이상\\n인류가 바퀴벌레 개체수를 줄일 수 있는 단하나의방법은 요리해먹기가아닐까\n",
      "8                                       그래 샐러드가 참 맛있었어\n",
      "9                                          난 네 조상의 친구야\n",
      "Name: Content, dtype: object\n",
      "0    Twitter Creator House Party💙\\n8주간의 #트위터크리에이터 프...\n",
      "1                         오늘 트위터 크리에이터 분들 덕에 피드 다 꿀잼이네\n",
      "2    ‘개발자가 되고 싶다면 트위터하세요’ \\n트위터 크리에이터 프로그램에 참여하신 클로...\n",
      "3               난 트위터에도\\n네이버블로그에도 무보수크리에이터 하는데\\n진짜 무보수\n",
      "4    앗 이제 트위터 크리에이터니까 에어팟 맥스는 사치재가 아니라 ‘업무’를 위한 투자가...\n",
      "5                              트위터 크리에이터 몇 분 선정된 거지...\n",
      "6    트위터 크리에이터 오리엔테이션도 있다는데 온라인으로 진행된다 해서 실망했어요. 오프...\n",
      "7                                트위터 크리에이터로 선정되었다 합니다.\n",
      "8    트위터의 많은 인사 담당자님들에게 질문합니다.\\n[아까 한 트친께서 '인레님은 트위...\n",
      "9    트위터 크리에이터는 의무적으로 스페이스를 진행하기만 하면 되는 건가? 트위터가 무슨...\n",
      "Name: Content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for item in ('Jeju','Line','Hash','Space','Key','Creator'):\n",
    "    df=pd.read_sql('''SELECT DISTINCT *\n",
    "                        FROM {0} \n",
    "                        LEFT JOIN {1} \n",
    "                        ON {0}.Username = {1}.Username\n",
    "                        '''.format(item+'_Users',item+'_Tweets'),conn\n",
    "                        )\n",
    "    df.to_csv(item+'_join.csv')\n",
    "    print(df.Content.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2a31f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
